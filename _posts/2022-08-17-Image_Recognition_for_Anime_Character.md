---
title: "Review: Image Recognition for Anime Character(PyConHK 2018)"
header:
excerpt: 2022-08-17 파이썬 딥러닝을 이용한 애니 캐릭터 인식 연구 리뷰
date: 2022-08-17
tags:
  - languages:Korean
  - tags:anime
  - tags:deep learning
---

{% include video id="sQ37OE_1EfY" provider="youtube" %}

<div class="notice">
#### 요약
기존의 사진 기반 얼굴 인식 모델로는 애니메이션 캐릭터 얼굴을 올바르게 분류해낼 수 없다. 따라서 애니메이션 캐릭터 얼굴 데이터를 기반으로 새로운 모델을 학습시켜야 한다. 그러나 이 과정에서 데이터셋 부족, 이미지 인덱싱(indexing) 등의 문제가 존재한다. 이를 위해 Transfer Learning을 이용했으며, 기존 모델들과 비교해본 결과 저자의 MoeFlow가 88.6%의 분류 정확도를 보였다. 그러나 측면 얼굴 인식 등은 안되는 한계가 존재했다.

- Blog: https://freedomofkeima.com/blog/
- Github Repo: https://github.com/freedomofkeima/transfer-learning-anime/
</div>

### 인상깊었던 점
가장 인상깊었던 점은 (당연하게 여길 수도 있지만) 기존 사진 기반 얼굴 인식 모델로는 애니메이션 캐릭터 얼굴을 올바르게 인식해낼 수 없다는 부분이었습니다. 이를 보면서 최근에 들었던 두 가지 강연을 떠올렸습니다. 

**첫 번째는 [Stanford cs231n](http://cs231n.stanford.edu/)** 입니다. 이 강의는 컴퓨터 비전이라는 분야가 실제 인간의 시각 정보 처리 과정을 컴퓨터라는 기계에 적용하여 얼마나 잘 인식시키냐라는 점에 초점이 맞춰져 있다는 점을 잘 보여주는 강의입니다. 컴퓨터가 사진 기반 얼굴 모델을 학습해서 애니메이션 캐릭터 얼굴을 인식하지 못한다는 점은 2D 얼굴과 3D 얼굴의 특성이 매우 다르며, 데포르메화 된 얼굴을 인간 역시 처음부터 사람 얼굴로 인식하지 않을지도 모른다는 가능성을 내포하고 있다고 생각됩니다.

**두 번째는 NAVER AI Lab 전상혁 연구원님의 [UNIST AIGS 강연](https://docs.google.com/presentation/d/1NNftqS6BcCPd52tv8gWEjB34retYhP0FToOFBd9ewkQ/edit#slide=id.g1028e85a486_0_0)** 입니다. 설명 가능한 AI(Reliabel AI)라는 주제로 강연을 해주셨는데, 현재 SOTA 모델들은 정확도에만 집중하고 Logical Thinking을 하는 모델의 방향으로 더 나아가야 한다고 강조하셨었습니다. 실제로 여러 선배로부터 SOTA 모델들은 새로운 SOTA 모델이 나오면 쉽게 버려지는 측면이 있고, 흔히 말하는 배 사진을 보고 배라고 인식하는 것이 아닌 배경인 바다를 보고 학습하는 등의 Cheating으로 Overfitting되어 정확도를 높인다는 이야기도 들었었습니다. ILSVRC의 AlexNet, ResNet 등도 결코 이러한 문제에서 자유로울 수 없을 것입니다.

결국 핵심은 양질의 데이터셋입니다. 크게 (1) 데이터셋의 양, (2) 데이터셋의 품질, (3) 데이터셋의 라벨링, 그리고 부가적으로 (4) 학습 과정에서 Bias를 줄일 수 있는 데이터셋의 전처리, 이 네 가지를 생각해볼 수 있을 것입니다. 현재 애니메이션 관련 데이터셋은 당장 절대적인 양이 부족한 상황이며, 저작권이라는 문제로 묶여있기도 합니다. 또한, 그림체가 제각각인 점도 생각해야할 것입니다.

결론적으로 데이터셋이 애니메이션 캐릭터 얼굴 인식 분야의 상용화와 정확도를 높이는데 핵심적인 요소가 될 것이며, 이에 대한 해결방안으로 아래와 같은 부분을 생각해봐야 한다고 생각합니다.
1. 애니메이션 캐릭터 데이터셋의 생성
2. 애니메이션 캐릭터 데이터셋이 적게 들어가고도 잘 학습되는 모델의 개발
3. 연구 목적의 애니메이션 캐릭터 데이터셋 개방 및 공공데이터화
4. 인간과 컴퓨터의 사진/애니메이션 기반 얼굴 인식의 공통점과 차이점 파악(Reliable AI)

### 관심사와 연관지어 생각
예전에 애니메이션 캐릭터 이름이 기억이 나지 않아 [이미지로 애니메이션을 검색하는 사이트](https://saucenao.com/)를 이용해본 경험이 떠올랐습니다. 이처럼 애니메이션 캐릭터 데이터셋의 양과 질, 라벨링이 잘 되면 캐릭터들의 특성에 따라 분류하고 평가하여 인기순으로 정렬하고 나만의 새로운 개성 넘치는 캐릭터를 만드는데 도움을 주는, 작가들을 서포트해주는 서비스가 생길지도 모른다는 생각이 들었습니다. 그림 외에도 스토리 내적으로도 도움을 받을 수 있는 창의작업지원도구가 만들어지는 것입니다.

다만, 현재 그림 쪽에 집중하고 있는 입장에서는 씁쓸한 뉴스가 많습니다. 최근 엄청난 퀄리티를 자랑하던 만화 베르세르크의 미우라 켄타로 작가가 과로로 인해 사망하고, 헌터×헌터의 토가시 요시히로 작가는 심한 요통 때문에 앉아서 작업을 할 수 없는 나날이 몇 년째 지속되고 있습니다. 이노우에 타케히코 작가의 배가본드 역시 사실상 연재중단인 상황입니다. 이처럼 퀄리티를 너무 높이다보면 반복 작업이 많아지고, 작가는 아무리 위대한 작품을 써내려간다한들 건강이 악화되며 롱런할 수 없습니다. 인공지능을 이용한 만화 반복 작업 자동화 연구를 하면서 퀄리티도 유지하거나 높일 수 있는 방법을 찾는 이유도 만화라는 장르의 접근성을 높일 뿐 아니라 작가들의 인간다운 삶, 롱런할 수 있는 환경을 만들기 위해서입니다.

취미로 로맨스판타지 웹툰을 보면서 눈에 띄는 것 중 하나가 배경입니다. 배경이 캐릭터와 이질감이 들거나, 어디서 본 듯한 3D 모델링된 건물인 경우가 많은데 이는 요즘 웹툰 작업을 스케치업 같은 3D툴로 만들어진 엔티티를 구매하여 붙여넣는 경우가 많기 때문입니다. 그나마 이러한 어색함을 가장 잘 해결하고 있는 분야가 게임인데, 젤다의 전설 Breath of the Wild, 길티기어 STRIVE, 원신 등이 좋은 예시입니다. 아래 사진들은 차례대로 젤대의 전설, 길티기어, 원신입니다.

![젤다의 전설](/assets/images/zelda.jpg)

![길티기어](/assets/images/ggst.jpg)

![원신](/assets/images/wonshin.jpg)

위에서 언급한 어색함을 최대한 줄이기 위해서 조금 더 시간과 노력을 들여서라도 3D 엔티티 기반 배경을 리터칭하거나, 빠른 작업 완료를 위해 3D 엔티티 기반 배경을 그대로 사용하는 것이 아닌, 캐릭터부터 배경까지 한 번에 모두 카툰 랜더링해버린 다음의 게임들은 만화작업에도 적용할 수 있을만한 요소가 분명히 있을 것입니다. 한 번 생성하는데는 많은 시간이 들지도 모르지만, 캐릭터나 배경을 한 번 생성하고 나면 그 이후에 추가적인 작업이나 인체 비례 붕괴없이 쉽게 작업할 수 있을 가능성이 충분히 있다고 생각합니다. 

다만, 이를 위해서는 두 가지 부분을 생각해봐야하는데, 먼저 독자 입장에서는 배경과 캐릭터 간의 이질감을 얼마나 인식하고 느끼는지에 대해서 조사하고, 타협할 수 있는 부분은 타협해봐야할 것입니다. 이는 설문조사나 전문가를 통해 라벨링한 이미지 등을 통해 일반인들이 어떻게 인식하는지에 대한 통제된 실험으로 비교하고 알아볼 필요가 있을 것입니다. 두 번재로 만약 3D툴을 이용한 카툰 랜더링 방식을 차용할 경우, 연출을 위한 의도적인 왜곡은 어떻게 표현해야 하는지를 고민해봐야할 것입니다. 의도적으로 구도를 뭉개거나 왜곡하는 경우가 있는만큼 인체비례가 비교적 완벽하게 보여지는 3D툴에서는 이를 어떻게 해결해야하는지 그리고 독자들은 왜곡된 장면과 그렇지 않는 장면을 어떻게 느끼고 선호하는지 역시 연구가 필요할 것입니다.

### 앞으로 나아가야할 점
강연에서 저자는 단순히 모델 개발뿐만이 아닌, Demo 서비스 개발 및 피드백, 다른 모델과의 비교 등도 잘 진행했습니다. [서류탈락하는 개발자 포트폴리오의 특징](https://velog.io/@dongyi/%EB%82%B4-%ED%8F%AC%ED%8A%B8%ED%8F%B4%EB%A6%AC%EC%98%A4%EA%B0%80-%EC%84%9C%EB%A5%98%ED%83%88%EB%9D%BD%EC%9D%B8-%EC%9D%B4%EC%9C%A0-%ED%94%84%EB%A1%9C%EC%A0%9D%ED%8A%B8-%EC%9D%B4%EB%A0%87%EA%B2%8C-%ED%95%B4%EB%B3%B4%EC%84%B8%EC%9A%94)이라는 글을 읽은 적이 있습니다. 해당 링크의 나와있는 프로젝트 자가진단이라는 문단의 10가지 요소에서 저는 아직 1-2개도 제대로 할 수 있다고 자신있게 말하기 어렵습니다.

그동안 저는 단순히 구현만 해왔지만, 이를 실질적으로 평가받기 위해서는 Demo 서비스 publish, 다른 연구 사례들과의 비교도 객관적으로 납득할 수 있을만한 방법을 고민할 필요가 있습니다. 이를 위해 기초적인 Web 지식, AWS 같은 PaaS를 사용하는 법, 비교 연구와 평가 지표 등에 대한 공부가 더 필요할 것 같습니다.

또한, 위에서 말한 카툰 랜더링과 관련해서도 블랜더 같은 툴에 대한 공부, 2D뿐만이 아닌 3D 컴퓨터 비전 지식, 3D를 효과적으로 2D로 옮기고 윤곽선을 잘 나태내는 방법 역시 더 알아봐야할 것입니다.

### 현장에 있었다면 어떤 질문을?
비록 PyCon에 없었기 때문에 질문은 할 수 없었지만, 제가 만약 PyCon에서 세 가지 질문을 할 수 있었다면 아래와 같은 질문을 했을 것 같습니다.

**Q1.** 애니메이션 캐릭터 데이터셋의 Indexing/Labeling을 자동화할 수단이 있을까요? 또한, 모에 토너먼트 같은 대회가 정기적으로 열리는 일본 같은 경우는 캐릭터의 인기도에 대한 Rating을 해볼수도 있을 것 같은데 이를 어떻게 생각하시나요?
{: .notice}

**Q2.** 비슷하다고 생각할수도 있지만, 대부분의 출판만화에서 캐릭터들이 흑백으로 되어있어 채색이 되어있는 애니메이션 캐릭터에 비해 학습을 통해 feature를 알아내기가 더 힘들 것 같습니다. 애니메이션 캐릭터의 경우 채색 스타일 등을 Bias로 Overfitting된 결과를 보여줄 수도 있다고 생각하는데 혹시 출판만화 캐릭터들을 통해 학습해본 경험은 있으신가요?
{: .notice}

**Q3.** 캐릭터 사진을 Resizing하는 이유가 궁급합니다. Resizing 전/후로 성능 차이가 많이 달라지나요? 달라지면 그 이유는 무엇인지 궁금합니다.
{: .notice}